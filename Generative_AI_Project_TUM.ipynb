{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIArt20/TUM_AI_Project/blob/main/Generative_AI_Project_TUM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJpXpmjEYC_T"
      },
      "source": [
        "##Training a txt generative AI, TUM MODEL\n",
        "\n",
        "\n",
        "Hans-Peter Nowak, Sophie Weis, Amazing Mark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuNQ1XqgkTde"
      },
      "source": [
        "#Data input from .txt\n",
        "\n",
        "Choose the data input, txt only.\n",
        "\n",
        "Double input, choose two txt files of your choice:\n",
        "\n",
        "!wget https://raw.githubusercontent.com/peace-in-mind/Quran-Truth-Edition/master/English-Quran-plain-text.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoelkOrFY8bN",
        "outputId": "06aba28d-b022-4169-d3e4-29e56a1d5388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-14 07:22:10--  https://raw.githubusercontent.com/peace-in-mind/Quran-Truth-Edition/master/English-Quran-plain-text.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 869732 (849K) [text/plain]\n",
            "Saving to: ‘English-Quran-plain-text.txt’\n",
            "\n",
            "English-Quran-plain 100%[===================>] 849.35K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-08-14 07:22:11 (15.3 MB/s) - ‘English-Quran-plain-text.txt’ saved [869732/869732]\n",
            "\n",
            "--2023-08-14 07:22:11--  https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4451368 (4.2M) [text/plain]\n",
            "Saving to: ‘bible.txt’\n",
            "\n",
            "bible.txt           100%[===================>]   4.25M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-08-14 07:22:12 (49.1 MB/s) - ‘bible.txt’ saved [4451368/4451368]\n",
            "\n",
            "10.802771 M parameters\n",
            "step 0: train loss 4.5767, val loss 4.5801\n",
            "step 555: train loss 2.0059, val loss 2.0981\n",
            "step 1110: train loss 1.4952, val loss 1.6620\n",
            "step 1665: train loss 1.2899, val loss 1.4959\n",
            "step 2220: train loss 1.1884, val loss 1.4125\n",
            "step 2775: train loss 1.1239, val loss 1.3658\n",
            "step 3330: train loss 1.0759, val loss 1.3244\n",
            "step 3885: train loss 1.0357, val loss 1.2922\n",
            "step 4440: train loss 1.0050, val loss 1.2732\n",
            "step 4995: train loss 0.9827, val loss 1.2687\n",
            "step 5550: train loss 0.9610, val loss 1.2487\n",
            "step 5554: train loss 0.9591, val loss 1.2474\n",
            "\n",
            "\n",
            "17:24 They were hetethr unto their rain instrument: through the congregation\n",
            "wealth, that soest they were on of their doings siance: that soul do warn\n",
            "in thy servants.\n",
            "\n",
            "17:25 Whom could see me thich Qur spiplieeth in the Day of Judah,\n",
            "that hath sucked a victude, of what whosoever wo tribes.\n",
            "\n",
            "17:26 That shall the earth who to bind sheep stand a life and cry wing:\n",
            "and his brother heart to break with a builock, shall was an hirabim from\n",
            "the glory wherein therein, and to be brickens upon the idols.\n",
            "\n",
            "18:28 And he did suffered a trouble truth woman's guilty: and he was as\n",
            "great end strififiere with younder breade, that calame he cities of\n",
            "the land was even with in his cities.\n",
            "\n",
            "19:21 Then preserved him with the swine or his king, the few came\n",
            "forth all hine another, and taked them in an house since mong darimagents.\n",
            "\n",
            "19:22 And the man\n",
            "of his dead is filled mones, that he heareth the sabbath.\n",
            "\n",
            "18:23 And it came to pass, when Joshua gathered; for a weellahe herd\n",
            "lifted up evil way, and were not sigh: for the Levites, the prophet\n",
            "and gatheren.\n",
            "\n",
            "\n",
            "18:24 Then called me, whency Jesus otherwards, and came that we\n",
            "is, when David took it, then goeth wings in marquakes?  19:24 And he called\n",
            "a cloudd; as the iniquities were in the cedar of Fathest, and\n",
            "will not we kite to read it?  29:24 And will the people that were\n",
            "came threesnes and twety to meet from the strengthing\n",
            "of Zion, to be received: so shall not make goodls.\n",
            "\n",
            "29:35 Huredof his life of the wilderness were not exalted: he\n",
            "reigned three faitful to divise them things of solthin is betten, and\n",
            "that the fool is for the cholend, and into the field, to warm, as a\n",
            "desolate by fire, whose fan corrupt in the people of the evil rest of his\n",
            "people, chooseth in the snea. The dweolt of holing salraves shall be a chrowed\n",
            "drawn.\n",
            "\n",
            "11:8 So the discler of the Quribea, and stallow of the fat was soles,\n",
            "then [the den behind it death, and gave it for them from the Allas.\n",
            "\n",
            "12:10 And they quaxed for facesed to another him shall be healed.\n",
            "\n",
            "11:1 And then a wain carried forth are come on that Adod.\n",
            "\n",
            "12:20 And Samuelli put the door Abijah and the soiled\n",
            "with them, and set one of bread of the heathen treasure in the fighth.\n",
            "\n",
            "11:21 But he iddecised and stand.\n",
            "\n",
            "21:2 And Jehoiah the son of Sacai was made bradecamels' heatherd ponly\n",
            "in their idols, and goodly on the sons of Moab and the barles: and\n",
            "spake the Jews of Israel was lookisened away up fire all pieces, and when\n",
            "the which departeeth on the will Day said unto his plain, Lord, Put\n",
            "be in the weight of his dissts.\n",
            "\n",
            "34:3 He broughteth before the house of the ground.\n",
            "\n",
            "35:5 Now Pitistiesh four Lord, shall be much plague, and be asfolished to his\n",
            "dungers.\n",
            "\n",
            "34:7 Then chastisheth any stronges after his veal wings shall be come\n",
            "vie never hundred.\n",
            "\n",
            "34:8 Heth brought is multiply, as it are? when he will ten curse afroation?\n",
            "54:9 And he that is therebelieven cometh, and he the disbelieveth shall be\n",
            "sent found.\n",
            "\n",
            "33:8 But he shall serve a little Tophath from the horns of man, that he\n",
            "might eat every fruit in the heaven day of Israel.\n",
            "\n",
            "44:9 And the Lord commanded two to mount out of the ward, and the Hebruite\n",
            "shall remaineth: shall there be ascereted in this, and the fir ass thereof\n",
            "offer with evils be work by the plear of the LORD. And they shall bring into\n",
            "the flock ashament them.\n",
            "\n",
            "44:19 And their body were gone to wives; they shall stait them, and\n",
            "shall fram off the uncience of which their gathered; that it\n",
            "may between himself and the ivil above, and the other laid thereon shall\n",
            "bread the vileyard and places.\n",
            "\n",
            "44:30 And that is so that beareing for the shepherds: and the\n",
            "parts and the Levites shall also a grance, wand at his countenting.\n",
            "\n",
            "44:31 And when she art murmultiplies saw alm, they had walked besied\n",
            "barelock? at father bayed when he hid bless one, and where was it\n",
            "meastness; 34:32 Teach and was upon my heaven tower heart, and upwakes I\n",
            "changed her encused to pass, and exjecreel inherity, and broke you up verily\n",
            "bread, saith the LORD.\n",
            "\n",
            "35:34 And thou mattest tus upon usick chake not over us: and that ordieth\n",
            "cry out of it, nor conflumeing awaketh us he wing iron and work off: and it\n",
            "is dwellingth in the way of the breasts; for ward other which the same of\n",
            "the seas of the slandaugh, shalt thou rejoice of the publagues of the\n",
            "words of the house.\n",
            "\n",
            "24:34 And Benhadraphra had been in you the men of Babylon; and he\n",
            "said unto him, Where is set abundation that his river: the enye, and which\n",
            "offeneth whom he that I travel to disprosper.\n",
            "\n",
            "25:35 And if I bring catherupon out one up, there are house unto thee,\n",
            "that go of the place of thee open the righteous, then the king: 25:27\n",
            "And she shall appean for them in prosperecy, and shall say, Wherefar his\n",
            "kindreaseth the heeth alive.\n",
            "\n",
            "25:39 And the vesies the increased; thou gave her that prayeth horn him\n",
            "shall could not the recomining wing.\n",
            "\n",
            "25:29 The heatuth they bringeth to wi a snring if good?  24:32 Whoso gin reveal\n",
            "thou sent me: and the gods of the LORD reserteout, that misre from the\n",
            "two passession wheal\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "#Parameters\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 5555\n",
        "eval_interval = 555\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#CPU or GPU (Colab Pro Settings)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "\n",
        "#First Seed\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "#General Input Data\n",
        "!wget https://raw.githubusercontent.com/peace-in-mind/Quran-Truth-Edition/master/English-Quran-plain-text.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt\n",
        "\n",
        "with open('/content/English-Quran-plain-text.txt', 'r', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "with open('/content/bible.txt', 'r', encoding='utf-8') as f:\n",
        "    data2 = f.read()\n",
        "\n",
        "#Merging Data\n",
        "data += \"\\n\"\n",
        "data += data2\n",
        "\n",
        "with open ('file3.txt', 'w') as fp:\n",
        "    fp.write(data)\n",
        "\n",
        "with open('/content/file3.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "#Char Set\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "#Char Mapping\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "#Traning vs. Valdation Data\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "#n=% Of Training Data\n",
        "n = int(0.89*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "#Main Data Processing\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "#Define Lagugage Model\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "#Parameters Print\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "#Opimizer PyTorck\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "#Prediction from the traines Model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=5000)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}